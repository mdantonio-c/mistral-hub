#!/usr/bin/python3

# Copyright (C) 2020  Paolo Patruno <p.patruno@iperbole.bologna.it>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA
#
# Authors: Paolo Patruno <p.patruno@iperbole.bologna.it>

import argparse
import datetime
import errno
import logging
import os
import shutil
import subprocess
import sys
import tempfile

import dballe
from mistral.services.dballe import BeDballe
from restapi.confs import get_backend_url
from restapi.connectors import smtp
from restapi.services.detect import detector

_version = 1.0
stderr = sys.stderr
stdout = sys.stdout

default_date = (datetime.datetime.utcnow() - datetime.timedelta(days=7)).strftime(
    "%Y-%m-%d"
)

parser = argparse.ArgumentParser(description="Migrate data from dballe to arkimet.")
parser.add_argument("--version", action="version", version=f"%(prog)s {_version}")
parser.add_argument(
    "-a",
    "--arkiconf",
    dest="arkiconf",
    action="store",
    default="/rmap/arkimet/arkimet.conf",
    help="arkiserver to contact. Default: %(default)s",
)
parser.add_argument(
    "-d",
    "--dsn",
    dest="dsn",
    action="store",
    default="mysql:///rmap?user=rmap&password=rmap",
    help="arkiserver to contact. Default: %(default)s",
)
parser.add_argument(
    "-o",
    "--outputdir",
    dest="outputdir",
    action="store",
    default="/tmp/" + "/dballe2arkimet",
    help="output directory where to write data. Default: %(default)s",
)
parser.add_argument(
    "-f",
    "--file",
    dest="outputfile",
    action="store",
    default="dballe2arkimet.dat",
    help="output file name for data. Default: %(default)s",
)
parser.add_argument(
    "-e",
    "--date",
    dest="date",
    action="store",
    default=default_date,
    help="reference date (AAAA-MM-DD). Default: <today-7days>",
)
# parser.add_argument('-t', '--time', dest='time', action='store',
#                    default="00:00:00",
#                    help='reference time (HH:MM:SS). Default: %(default)s')
parser.add_argument(
    "-p",
    "--tempprefix",
    dest="tempprefix",
    action="store",
    default="/tmp/",
    help="Prefix for temporary work directory. Default: %(default)s",
)
parser.add_argument(
    "--cachedir",
    metavar="dir",
    action="store",
    type=str,
    default=None,
    help="cache directory for warped channels. Default: %(default)s",
)
parser.add_argument(
    "-v",
    "--verbose",
    action="store",
    type=bool,
    default=False,
    help="set verbosity level to DEBUG, Default: %(default)s",
)

opts = parser.parse_args()

date = datetime.date(*[int(e) for e in opts.date.split("-")])


class Error(Exception):
    """Base class for exceptions in this module."""

    pass


class TmpDirError(Error):
    """Exception raised setting temporary working dir.
    Attributes:
        expr -- input expression in which the error occurred
        msg  -- explanation of the error
    """

    def __init__(self, expr, msg):
        self.expr = expr
        self.msg = msg

    def __str__(self):
        return repr(self.msg) + "Dir: " + repr(self.expr)


class makeenv:
    def __init__(self, tempprefix=None):

        self.cwd = None

        if tempprefix is not None:
            # tempfile.tempdir=tempprefix
            tmp = tempfile.mkdtemp(prefix=tempprefix)
        else:
            tmp = tempfile.mkdtemp(prefix="/tmp/")

        logging.info("Working temporary directory: " + tmp)
        os.chdir(tmp)

        if not os.path.samefile(tmp, os.getcwd()):
            raise TmpDirError(
                (tmp, os.getcwd()), "Error testing cwd after chdir in tmp working dir"
            )
        else:
            self.cwd = tmp

        # prepare output directory
        try:
            os.makedirs(opts.outputdir)
        except OSError as exc:  # Python >2.5
            if exc.errno == errno.EEXIST and os.path.isdir(opts.outputdir):
                pass
            else:
                raise

    def delete(self):

        dangerouspaths = ("/", "/home", "/home/")

        if self.cwd is not None and self.cwd not in dangerouspaths:
            # print "remove working tree ",self.cwd
            shutil.rmtree(self.cwd)
        else:
            logging.info(
                "tempprefix is a dangerous path: do not remove temporary working directoy"
            )


def dballe2arkimet(date):
    logging.info("Start to migrate data to arkimet")
    rec = {"yearmax": date.year, "monthmax": date.month, "daymax": date.day}
    tmpdatafile = "tmpdatafile"
    db = dballe.DB.connect(opts.dsn)

    with db.transaction() as tr:
        exporter = dballe.Exporter("BUFR")
        with open(tmpdatafile, "wb") as tmpfile:
            for row in tr.query_messages(rec):
                tmpfile.write(exporter.to_binary(row.message))

        # ---------------- UPDATE JSON SUMMARY --------------------
        general_explorer = dballe.DBExplorer()
        json_summary = BeDballe.ARKI_JSON_SUMMARY_PATH
        json_summary_filtered = BeDballe.ARKI_JSON_SUMMARY_PATH_FILTERED

        with general_explorer.update() as updater:
            # Load existing json summary
            if os.path.exists(json_summary):
                with open(json_summary) as fd:
                    updater.add_json(fd.read())

            # Import files listed on command line
            importer = dballe.Importer("BUFR")
            with importer.from_file(tmpdatafile) as f:
                # updater.add_messages(f)
                # for the new version
                updater.add_messages(f, station_data=False, data=True)

        # Write out the general summary
        with open(json_summary, "wt") as fd:
            fd.write(general_explorer.to_json())

        # create the filtered summary
        all_nets = general_explorer.all_reports
        filtered_explorer = dballe.DBExplorer()
        for net in all_nets:
            if net not in BeDballe.MAPS_NETWORK_FILTER:
                general_explorer.set_filter({"rep_memo": net})
                # add the filtered explorer to the general one
                with filtered_explorer.update() as updater:
                    updater.add_explorer(general_explorer)

        # export the filtered explorer to a json file
        with open(json_summary_filtered, "wt") as fd:
            fd.write(filtered_explorer.to_json())

        # ---------------------------------------------------------

        returncode = subprocess.call(
            (
                "arki-scan",
                "--dispatch=" + opts.arkiconf,
                "bufr:" + tmpdatafile,
                "--summary",
                "--dump",
                "--status",
            ),
            stderr=stderr,
            stdout=stdout,
        )

        logging.info("End to migrate data to arkimet")
        logging.info("Return status: %s" % (returncode))

        if returncode == 0 or returncode == 2:
            logging.info("Start to delete data from dballe")
            tr.remove_data(rec)
            logging.info("End to delete data from dballe")
        else:
            tr.rollback()
            logging.error("Error migrate data from dballe to arkimet")
            logging.warning("Do not delete data from dballe")
            # sent alert by mail
            smtp_client = smtp.get_instance()
            host = get_backend_url()
            smtp_client.send(
                "Error migrate data from dballe to arkimet: data not deleted from DBalle",
                f"Alert from {host} : Migration error",
                to_address="b.chiavarini@cineca.it",
            )


def main():
    # Get an instance of a logger

    # we want work like fortran ? TODO
    #  call getenv("LOG4_APPLICATION_NAME",LOG4_APPLICATION_NAME)
    #  call getenv("LOG4_APPLICATION_ID",LOG4_APPLICATION_ID)

    if opts.verbose:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    logger = logging.getLogger(__name__)

    logger.info("start")
    try:
        logger.info("makeenv")
        env = makeenv(tempprefix=opts.tempprefix)
    except TmpDirError as e:
        logger.exception(e)
        raise
    except BaseException:
        logger.exception("premature end")
        raise

    if opts.cachedir is None:
        opts.cachedir = env.cwd

    try:
        logger.info("start dballe2arkimet")
        dballe2arkimet(date)

    except BaseException:
        logger.exception("Error happen")
        raise
    finally:
        env.delete()
        logger.info("end")


if __name__ == "__main__":
    stdout.write(sys.argv[0] + " started with pid %d\n" % os.getpid())
    stdout.write(sys.argv[0] + " stdout output\n")
    stderr.write(sys.argv[0] + " stderr output\n")

    # (this code was run as script)
    sys.exit(main())
